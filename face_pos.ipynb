{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Qt8rIevs2PLw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from random import sample\n",
        "import cv2\n",
        "import keras\n",
        "import keras.backend as K\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random as rn\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import xml.etree.ElementTree as ET\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "from tensorflow.image import grayscale_to_rgb\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.python.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50,preprocess_input\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split,KFold, cross_val_score\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img, img_to_array\n",
        "from tensorflow.keras.metrics import mean_squared_error as mse\n",
        "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D,BatchNormalization,Dropout,Conv2D,MaxPool2D"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mse([[1,2],[1,2]],[[3,6],[3,6]])#, mse([1])\n",
        "# mse([0],[3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPIqLCbszS9g",
        "outputId": "2856e816-34ca-42d0-8d07-b78744f7e619"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([10, 10], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIAWoEBhSmQT",
        "outputId": "4a4de69e-b460-410d-95d8-411c162c81e6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data():\n",
        "\n",
        "    labels = []    \n",
        "    imgs=[]\n",
        "    path = '/content/drive/MyDrive/outputpairs/'\n",
        "    for input_path in os.listdir(path):\n",
        "\n",
        "        facehair_path = path+'/'+input_path + '/facehair.png'\n",
        "        garment_top_path = path+'/'+input_path + '/garment_top.png'\n",
        "        positions_path = path+'/'+input_path + '/positions.json'\n",
        "        # facehair_img = cv2.imread(facehair_path,cv2.IMREAD_UNCHANGED)\n",
        "        # facehair_img = cv2.cvtColor(facehair_img, cv2.COLOR_BGR2RGB)\n",
        "        facehair_img = np.array(Image.open(facehair_path).convert('L'))\n",
        "        garment_top_img = np.array(Image.open(garment_top_path).convert('L'))[:512,:512]\n",
        "\n",
        "        shape = facehair_img.shape\n",
        "        gap = max(shape)-min(shape) \n",
        "        facehair_img = cv2.resize(np.pad(facehair_img, [(0,),(gap//2,)]),(512,512))\n",
        "        img = np.array([facehair_img, garment_top_img])\n",
        "        img = np.einsum('ijk->jki',img)\n",
        "        # garment_top_img = cv2.imread(garment_top_path,cv2.IMREAD_UNCHANGED)\n",
        "        positions = json.load(open(positions_path))\n",
        "\n",
        "        x = positions['x']\n",
        "        y = positions['y']\n",
        "        labels.append([x,y])\n",
        "        imgs.append(img)\n",
        "                                \n",
        "    return np.array(imgs), np.array(labels)"
      ],
      "metadata": {
        "id": "MbgQAyyp2VjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/outputpairs/'\n",
        "out = '/content/drive/MyDrive/TRI/test/'\n",
        "\n",
        "for input_path in sample(os.listdir(path),50):\n",
        "\n",
        "    facehair_path = path+'/'+input_path + '/facehair.png'\n",
        "    garment_top_path = path+'/'+input_path + '/garment_top.png'\n",
        "    positions_path = path+'/'+input_path + '/positions.json'\n",
        "    # facehair_img = cv2.imread(facehair_path,cv2.IMREAD_UNCHANGED)\n",
        "    # facehair_img = cv2.cvtColor(facehair_img, cv2.COLOR_BGR2RGB)\n",
        "    # face = Image.open(facehair_path)\n",
        "    facehair_img = np.array(Image.open(facehair_path).convert('L'))\n",
        "\n",
        "    # garment = Image.open(garment_top_path)\n",
        "    garment_top_img = np.array(Image.open(garment_top_path).convert('L'))[:512,:512]\n",
        "\n",
        "    face = cv2.imread(facehair_path,cv2.IMREAD_UNCHANGED)\n",
        "    face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
        "    garment = cv2.imread(garment_top_path,cv2.IMREAD_UNCHANGED)\n",
        "    garment = cv2.cvtColor(garment, cv2.COLOR_BGR2RGB)\n",
        "    \n",
        "    shape = facehair_img.shape\n",
        "    gap = max(shape)-min(shape) \n",
        "    facehair_img = cv2.resize(np.pad(facehair_img, [(0,),(gap//2,)]),(512,512))\n",
        "    img = np.array([facehair_img, garment_top_img])\n",
        "    img = np.array([np.einsum('ijk->jki',img)])\n",
        "    positions = json.load(open(positions_path))\n",
        "\n",
        "    [[x,y]] = model.predict(img)\n",
        "    x,y = int(x),int(y)\n",
        "    h,w,c = face.shape\n",
        "    # print(h,w,c,x,y)\n",
        "    output_img = garment\n",
        "    output_img[y:y+h,x:x+w] = face\n",
        "    plt.imsave(out + input_path +'.png',output_img)\n",
        "    print(x,y,positions['x'],positions['y'])\n",
        "    # plt.imshow(output_img)\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAtDp79wVkww",
        "outputId": "fb5cf46a-e536-45f3-a7eb-3cc0dbcd1fcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 24ms/step\n",
            "326 0 324 33\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "283 0 264 10\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "294 0 319 10\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "271 0 319 74\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "303 0 291 55\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "250 0 249 15\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "271 0 273 10\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "304 0 311 14\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "275 0 295 12\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "348 0 336 11\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "259 0 266 13\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "282 0 297 20\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "258 0 251 12\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "260 0 259 17\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "371 0 386 14\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "393 0 412 56\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "224 0 260 15\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "268 0 277 30\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "271 0 235 14\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "424 0 414 26\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "246 0 242 30\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "268 0 233 13\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "251 0 235 39\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "298 0 252 16\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "321 0 317 0\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "254 0 226 35\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "204 0 272 8\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "368 0 407 13\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "208 0 181 17\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "248 0 248 15\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "294 0 284 15\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "345 0 314 8\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "318 0 276 11\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "303 0 290 18\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "264 0 266 34\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "248 0 261 14\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "253 0 263 86\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "317 0 320 20\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "338 0 330 5\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "0 8 155 21\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "416 0 442 11\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "283 0 282 31\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "392 0 445 15\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "282 0 281 48\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "267 0 276 26\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "323 0 294 12\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "233 0 221 20\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "301 0 293 29\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "324 0 298 22\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "446 0 372 27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = load_data()"
      ],
      "metadata": {
        "id": "BToVnAtw5AdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/TRI/data.npy', 'wb') as f:\n",
        "    np.save(f, X)\n",
        "    np.save(f, y)"
      ],
      "metadata": {
        "id": "9KXu8TcIEXs4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/TRI/data.npy', 'rb') as f:\n",
        "    X = np.load(f)\n",
        "    y = np.load(f)"
      ],
      "metadata": {
        "id": "lHGLK2VxsvVv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "54486c09",
        "outputId": "73662e9f-a318-4d7e-b54d-cdba1540912c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3126, 512, 512, 2), (3126, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "X.shape, y.shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
      ],
      "metadata": {
        "id": "lXkYMdezFkiy"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0d99662",
        "outputId": "98fa9896-561c-48dd-e1be-3bc55c10d7b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 3s 0us/step\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 512, 512, 3)       57        \n",
            "                                                                 \n",
            " resnet50 (Functional)       (None, 2048)              23587712  \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               1049088   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512)               0         \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 512)              2048      \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 256)              1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 2)                 514       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 24,771,771\n",
            "Trainable params: 24,717,115\n",
            "Non-trainable params: 54,656\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "# model.add(ResNet50(include_top=False, weights=None, input_shape=(512,512,2),pooling='max'))\n",
        "model.add(keras.layers.Input(shape=(512,512,2)))\n",
        "model.add(Conv2D(3,(3,3),padding='same'))\n",
        "model.add(ResNet50(include_top=False, weights='imagenet', pooling='max'))\n",
        "# model.layers[0].layers\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(2, activation='relu'))\n",
        "\n",
        "# model.layers[0].trainable = False\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f86f4ea6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b748817a-9f79-4a95-b383-f47a5b50f5f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "optimizer = Adam(lr=0.00002)\n",
        "model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mse'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0e4a64c0"
      },
      "outputs": [],
      "source": [
        "# earlystopping = EarlyStopping(monitor='loss', verbose=1, patience=10, min_delta=0.02)\n",
        "checkpoint = ModelCheckpoint('/content/drive/MyDrive/TRI/face3.h5', monitor='val_loss', mode='min', initial_value_threshold=800)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights('/content/drive/MyDrive/TRI/face2.h5')"
      ],
      "metadata": {
        "id": "HlcxdyUyEPBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9403c35c",
        "outputId": "a903d732-e3f9-410e-de92-f70bfd2fdb06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "176/176 [==============================] - 156s 858ms/step - loss: 1116.7073 - mse: 1116.7073 - val_loss: 941.3594 - val_mse: 941.3594\n",
            "Epoch 2/10\n",
            "176/176 [==============================] - 150s 854ms/step - loss: 1070.7913 - mse: 1070.7913 - val_loss: 1051.5486 - val_mse: 1051.5486\n",
            "Epoch 3/10\n",
            "176/176 [==============================] - 151s 856ms/step - loss: 1063.5145 - mse: 1063.5145 - val_loss: 1071.8879 - val_mse: 1071.8879\n",
            "Epoch 4/10\n",
            "176/176 [==============================] - 152s 866ms/step - loss: 1064.4149 - mse: 1064.4149 - val_loss: 1102.7725 - val_mse: 1102.7725\n",
            "Epoch 5/10\n",
            "176/176 [==============================] - 151s 860ms/step - loss: 1060.3390 - mse: 1060.3390 - val_loss: 943.8538 - val_mse: 943.8538\n",
            "Epoch 6/10\n",
            "176/176 [==============================] - 151s 857ms/step - loss: 1082.6096 - mse: 1082.6096 - val_loss: 972.6164 - val_mse: 972.6164\n",
            "Epoch 7/10\n",
            "176/176 [==============================] - 151s 856ms/step - loss: 1067.1414 - mse: 1067.1414 - val_loss: 1066.8251 - val_mse: 1066.8251\n",
            "Epoch 8/10\n",
            "176/176 [==============================] - 151s 856ms/step - loss: 1080.7760 - mse: 1080.7760 - val_loss: 920.3068 - val_mse: 920.3068\n",
            "Epoch 9/10\n",
            "176/176 [==============================] - 150s 854ms/step - loss: 1042.3196 - mse: 1042.3196 - val_loss: 896.6016 - val_mse: 896.6016\n",
            "Epoch 10/10\n",
            "176/176 [==============================] - 150s 854ms/step - loss: 1036.0063 - mse: 1036.0063 - val_loss: 834.1182 - val_mse: 834.1182\n"
          ]
        }
      ],
      "source": [
        "#batch_size = 32\n",
        "history = model.fit(X_train,y_train,batch_size=16,validation_data=(X_test,y_test),\n",
        "                              epochs=10, callbacks=[checkpoint])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#batch_size = 32\n",
        "history = model.fit(X_train,y_train,batch_size=16,validation_data=(X_test,y_test),\n",
        "                              epochs=5, callbacks=[checkpoint])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r72VO03BRRhV",
        "outputId": "faafe67a-354e-4762-b03f-f6fcb2c12ebf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "176/176 [==============================] - 167s 879ms/step - loss: 1055.0948 - mse: 1055.0948 - val_loss: 848.3727 - val_mse: 848.3727\n",
            "Epoch 2/5\n",
            "176/176 [==============================] - 149s 848ms/step - loss: 1008.1448 - mse: 1008.1448 - val_loss: 871.4346 - val_mse: 871.4346\n",
            "Epoch 3/5\n",
            "176/176 [==============================] - 149s 847ms/step - loss: 1026.8696 - mse: 1026.8696 - val_loss: 856.0651 - val_mse: 856.0651\n",
            "Epoch 4/5\n",
            "176/176 [==============================] - 150s 852ms/step - loss: 993.6096 - mse: 993.6096 - val_loss: 843.6117 - val_mse: 843.6117\n",
            "Epoch 5/5\n",
            "176/176 [==============================] - 149s 848ms/step - loss: 996.3391 - mse: 996.3391 - val_loss: 842.8549 - val_mse: 842.8549\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bee4b84f"
      },
      "outputs": [],
      "source": [
        "K.set_value(model.optimizer.learning_rate, 0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "313965c5"
      },
      "outputs": [],
      "source": [
        "for layer in model.layers[1].layers[-70:]:\n",
        "    layer.trainable = True"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using MAPE and layer freezing"
      ],
      "metadata": {
        "id": "YWYkrHKXDAIy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "# model.add(ResNet50(include_top=False, weights=None, input_shape=(512,512,2),pooling='max'))\n",
        "model.add(keras.layers.Input(shape=(512,512,2)))\n",
        "model.add(Conv2D(3,(3,3),padding='same'))\n",
        "model.add(ResNet50(include_top=False, weights='imagenet', pooling='max'))\n",
        "# model.layers[0].layers\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(2, activation='linear'))\n",
        "\n",
        "# model.layers[0].trainable = False\n",
        "# model.summary()\n"
      ],
      "metadata": {
        "id": "RAuqO99HDFk0"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.layers[1].trainable = True"
      ],
      "metadata": {
        "id": "nDsE4V5yDgxU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6gPHiOjDwG-",
        "outputId": "f8809f1f-0b39-4564-af09-9e2c2b92e251"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_1 (Conv2D)           (None, 512, 512, 3)       57        \n",
            "                                                                 \n",
            " resnet50 (Functional)       (None, 2048)              23587712  \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1024)              2098176   \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 1024)              0         \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 1024)             4096      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 256)               262400    \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 256)              1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 2)                 514       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,953,979\n",
            "Trainable params: 25,898,299\n",
            "Non-trainable params: 55,680\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "L96u6Ea3D_3R"
      },
      "outputs": [],
      "source": [
        "optimizer = Adam(lr=0.0005)\n",
        "model.compile(optimizer=optimizer, loss='mean_absolute_error', metrics=['mae'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "fWhcgV6jD_3T"
      },
      "outputs": [],
      "source": [
        "# earlystopping = EarlyStopping(monitor='loss', verbose=1, patience=10, min_delta=0.02)\n",
        "checkpoint = ModelCheckpoint('/content/drive/MyDrive/TRI/face6.h5', monitor='val_loss', mode='min', initial_value_threshold=156)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights('/content/drive/MyDrive/TRI/face5.h5')"
      ],
      "metadata": {
        "id": "h8X3DxaXD_3U"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights('/content/drive/MyDrive/TRI/face6.h5')"
      ],
      "metadata": {
        "id": "NBOBFLXbl8uo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "outputId": "c8bfb575-ca02-4990-c7ae-e6ac74461e3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uw8Zd_sMD_3V"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "176/176 [==============================] - 173s 876ms/step - loss: 156.9214 - mae: 156.9214 - val_loss: 154.6269 - val_mae: 154.6269\n",
            "Epoch 2/10\n",
            "176/176 [==============================] - 146s 831ms/step - loss: 153.0546 - mae: 153.0546 - val_loss: 148.3881 - val_mae: 148.3881\n",
            "Epoch 3/10\n",
            "176/176 [==============================] - 146s 830ms/step - loss: 145.8095 - mae: 145.8095 - val_loss: 143.4685 - val_mae: 143.4685\n",
            "Epoch 4/10\n",
            "176/176 [==============================] - 146s 830ms/step - loss: 137.4012 - mae: 137.4012 - val_loss: 133.7784 - val_mae: 133.7784\n",
            "Epoch 5/10\n",
            "176/176 [==============================] - 146s 828ms/step - loss: 128.5354 - mae: 128.5354 - val_loss: 120.8517 - val_mae: 120.8517\n",
            "Epoch 6/10\n",
            "176/176 [==============================] - 146s 831ms/step - loss: 117.8687 - mae: 117.8687 - val_loss: 112.5677 - val_mae: 112.5677\n",
            "Epoch 7/10\n",
            "176/176 [==============================] - 146s 830ms/step - loss: 104.9000 - mae: 104.9000 - val_loss: 96.5987 - val_mae: 96.5987\n",
            "Epoch 8/10\n",
            "176/176 [==============================] - 146s 832ms/step - loss: 89.9121 - mae: 89.9121 - val_loss: 82.3114 - val_mae: 82.3114\n",
            "Epoch 9/10\n",
            "176/176 [==============================] - 146s 828ms/step - loss: 73.0371 - mae: 73.0371 - val_loss: 57.6986 - val_mae: 57.6986\n",
            "Epoch 10/10\n",
            "176/176 [==============================] - 146s 828ms/step - loss: 55.3882 - mae: 55.3882 - val_loss: 35.2462 - val_mae: 35.2462\n"
          ]
        }
      ],
      "source": [
        "#batch_size = 32\n",
        "history = model.fit(X_train,y_train,batch_size=16,validation_data=(X_test,y_test),\n",
        "                              epochs=10, callbacks=[checkpoint])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train,y_train,batch_size=16,validation_data=(X_test,y_test),\n",
        "                              epochs=5, callbacks=[checkpoint])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ktp9x0x9D45S",
        "outputId": "b115d2de-234a-4376-8968-623c67a72f09"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "176/176 [==============================] - 149s 818ms/step - loss: 40.8800 - mae: 40.8800 - val_loss: 29.8984 - val_mae: 29.8984\n",
            "Epoch 2/5\n",
            "176/176 [==============================] - 147s 834ms/step - loss: 31.8392 - mae: 31.8392 - val_loss: 24.6674 - val_mae: 24.6674\n",
            "Epoch 3/5\n",
            "176/176 [==============================] - 147s 835ms/step - loss: 27.8126 - mae: 27.8126 - val_loss: 32.7721 - val_mae: 32.7721\n",
            "Epoch 4/5\n",
            "176/176 [==============================] - 145s 826ms/step - loss: 26.7258 - mae: 26.7258 - val_loss: 25.3033 - val_mae: 25.3033\n",
            "Epoch 5/5\n",
            "176/176 [==============================] - 145s 826ms/step - loss: 26.7652 - mae: 26.7652 - val_loss: 24.6036 - val_mae: 24.6036\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train,y_train,batch_size=16,validation_data=(X_test,y_test),\n",
        "                              epochs=5, callbacks=[checkpoint])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OPdEjfhoOtD",
        "outputId": "adbcdcbe-ad96-4a38-d492-94bbfbdf820e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "176/176 [==============================] - 174s 884ms/step - loss: 27.4739 - mae: 27.4739 - val_loss: 24.7931 - val_mae: 24.7931\n",
            "Epoch 2/5\n",
            "176/176 [==============================] - 150s 850ms/step - loss: 27.4106 - mae: 27.4106 - val_loss: 24.7793 - val_mae: 24.7793\n",
            "Epoch 3/5\n",
            "176/176 [==============================] - 148s 841ms/step - loss: 27.1157 - mae: 27.1157 - val_loss: 24.9379 - val_mae: 24.9379\n",
            "Epoch 4/5\n",
            "176/176 [==============================] - 148s 841ms/step - loss: 27.3561 - mae: 27.3561 - val_loss: 24.7209 - val_mae: 24.7209\n",
            "Epoch 5/5\n",
            "176/176 [==============================] - 148s 839ms/step - loss: 27.3170 - mae: 27.3170 - val_loss: 24.4947 - val_mae: 24.4947\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/outputpairs/'\n",
        "out = '/content/drive/MyDrive/TRI/test2/'\n",
        "\n",
        "for input_path in sample(os.listdir(path),20):\n",
        "\n",
        "    facehair_path = path+'/'+input_path + '/facehair.png'\n",
        "    garment_top_path = path+'/'+input_path + '/garment_top.png'\n",
        "    positions_path = path+'/'+input_path + '/positions.json'\n",
        "    # facehair_img = cv2.imread(facehair_path,cv2.IMREAD_UNCHANGED)\n",
        "    # facehair_img = cv2.cvtColor(facehair_img, cv2.COLOR_BGR2RGB)\n",
        "    # face = Image.open(facehair_path)\n",
        "    facehair_img = np.array(Image.open(facehair_path).convert('L'))\n",
        "\n",
        "    # garment = Image.open(garment_top_path)\n",
        "    garment_top_img = np.array(Image.open(garment_top_path).convert('L'))[:512,:512]\n",
        "\n",
        "    face = cv2.imread(facehair_path,cv2.IMREAD_UNCHANGED)\n",
        "    face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
        "    garment = cv2.imread(garment_top_path,cv2.IMREAD_UNCHANGED)\n",
        "    garment = cv2.cvtColor(garment, cv2.COLOR_BGR2RGB)\n",
        "    \n",
        "    shape = facehair_img.shape\n",
        "    gap = max(shape)-min(shape) \n",
        "    facehair_img = cv2.resize(np.pad(facehair_img, [(0,),(gap//2,)]),(512,512))\n",
        "    img = np.array([facehair_img, garment_top_img])\n",
        "    img = np.array([np.einsum('ijk->jki',img)])\n",
        "    positions = json.load(open(positions_path))\n",
        "\n",
        "    [[x,y]] = model.predict(img)\n",
        "    x,y = int(x),int(y)\n",
        "    h,w,c = face.shape\n",
        "    # print(h,w,c,x,y)\n",
        "    output_img = garment\n",
        "    output_img[y:y+h,x:x+w] = face\n",
        "    plt.imsave(out + input_path +'.png',output_img)\n",
        "    print(x,y,positions['x'],positions['y'])\n",
        "    # plt.imshow(output_img)\n",
        "    "
      ],
      "metadata": {
        "id": "HN5dVr1AldZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ltjk9NPARXeJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}